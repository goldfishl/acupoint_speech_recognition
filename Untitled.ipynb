{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f6e4f7-76bb-491c-9486-c0fac2a69edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram\n",
    "from IPython.display import Audio\n",
    "\n",
    "from src import audio_proc as ap\n",
    "from src import reader\n",
    "\n",
    "\n",
    "all_words = reader.get_all_wav()\n",
    "raw_pres = reader.get_raw_pres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe771b9-96d3-4ef7-ade6-6d5e7bbf382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a list of missing words\n",
    "# There's not a lot of them, I've noted some\n",
    "# observations down in Clean.txt\n",
    "missing = []\n",
    "for res, optional in raw_pres:\n",
    "    for item in res:\n",
    "        if item not in all_words:\n",
    "            if item not in missing:\n",
    "                missing.append(item)\n",
    "    for term in optional:\n",
    "        for item in term:\n",
    "            if item not in all_words:\n",
    "                if item not in missing:\n",
    "                    missing.append(item)\n",
    "with open(\"data/combined_prescription/Missing.txt\", \"w\") as out_file:\n",
    "    out_file.write(\"\\n\".join(missing + [\"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce3a568-58d9-430d-b030-0c520feea9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['肩前', '颈臂', '腰夹脊', '十二井穴', '局部经穴', '颈夹脊', '胸夹脊', '十井', '夹脊穴', '膝眼', '胆囊穴']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc00bd8c-3ab8-4419-bedd-3b268fc57c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "\n",
    "# 用于记录音频sample index的队列\n",
    "class IndexQueue():\n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "        self.count = 0\n",
    "    def put(self, data):\n",
    "        self.queue.append(data)\n",
    "    def get(self):\n",
    "        if self.count == len(self.queue):\n",
    "            return False\n",
    "        self.count += 1\n",
    "        return self.queue[self.count-1]\n",
    "    def is_empty(self):\n",
    "        if self.count == len(self.queue):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "    def __str__(self):\n",
    "        return str(self.queue)\n",
    "    \n",
    "    \n",
    "def get_window_median(sequence_length, window_size, window_stride):\n",
    "    num_window = int( (sequence_length - window_size + window_stride) / window_stride )\n",
    "    \n",
    "    return list(range(int(window_size/2), sequence_length, window_stride))[:num_window]\n",
    "        \n",
    "\n",
    "\n",
    "def pres_generate(pres, all_words, max_permut=10, repeat=2):\n",
    "    # Generate audio from a single entry within raw_pres\n",
    "    # The algorithm works by generating all combinations of\n",
    "    # 主穴位 and 辅穴,\n",
    "    # then generate all permutations (TODO: limit permutations?)\n",
    "    # For each generated permutation, randomly sample from available\n",
    "    # speakers, and generate a maximum of 2 complete clips.\n",
    "    \n",
    "    # Intro/outtro time\n",
    "    max_fade_time = 2000  # in ms\n",
    "    \n",
    "    # Gap between each word is randomly sampled\n",
    "    # Depending on speaker style, the maximum is also randomly sampled\n",
    "    max_gap_time = 3000  # in ms\n",
    "    min_gap_time = 500  # in ms\n",
    "    max_gap_time = random.randrange(min_gap_time, max_gap_time)\n",
    "    \n",
    "    # 主穴位组 and 辅助穴组\n",
    "    # 一个主穴位组可能有零或多组辅助穴位，所以optional是一个list of list\n",
    "    res, optional = pres\n",
    "    \n",
    "    # Filter out missing words\n",
    "    res = [item for item in res if item in all_words]\n",
    "    optional = [[item for item in opt  if item in all_words] for opt in optional]\n",
    "    \n",
    "    # 添加原主穴组\n",
    "    all_res = [res]\n",
    "    # 添加所有主穴组和辅助穴组的组合\n",
    "    for item in optional:\n",
    "        all_res.append(res + item)\n",
    "        \n",
    "    \n",
    "    # Add permutation\n",
    "    # This part needs to be optimised\n",
    "    # (limit permutations to a maximum of 10 per entry maybe?)\n",
    "    all_permuts = []\n",
    "    for entry in all_res:\n",
    "        single_item_permut = list(itertools.permutations(entry, len(entry)))\n",
    "        random.shuffle(single_item_permut)\n",
    "        if len(single_item_permut) > max_permut:\n",
    "            single_item_permut = single_item_permut[:max_permut]\n",
    "        all_permuts += single_item_permut\n",
    "    \n",
    "    # Generate audio data\n",
    "    result = []\n",
    "    for pres in all_permuts:\n",
    "        for i in range(repeat):\n",
    "            # Generate a single complete audio clip\n",
    "            # randomly sample speakers for each word\n",
    "            # TODO: optimise speaker selection?\n",
    "            all_files = [random.choice(all_words[key])[1] for key in pres]\n",
    "            # Get actual audio data\n",
    "            # ap.load returns (data, fs) tuple,\n",
    "            # All wav files should have been converted to sample rate of\n",
    "            # ap.default_fs already, so \"fs\" should be consistent\n",
    "            all_data = [ap.load(file)[0] for file in all_files]\n",
    "            \n",
    "            # char transcription\n",
    "            index_queue=IndexQueue()\n",
    "\n",
    "            \n",
    "            # sample noise\n",
    "            # sample rate by default is ap.default_fs\n",
    "            \n",
    "            # intro\n",
    "            _time = random.randrange(0, max_fade_time)\n",
    "            wav_data_list = [ap.noise(_time)]\n",
    "            \n",
    "            # gaps\n",
    "            for data in all_data:\n",
    "                _time = random.randrange(min_gap_time, max_gap_time)\n",
    "                wav_data_list.append(ap.noise(_time))\n",
    "                _sample_index = len(np.concatenate(wav_data_list))\n",
    "                index_queue.put((_sample_index, \"B\"))\n",
    "                \n",
    "                wav_data_list.append(data)\n",
    "                _sample_index = len(np.concatenate(wav_data_list))\n",
    "                index_queue.put((_sample_index, \"I\"))\n",
    "\n",
    "                \n",
    "            # outtro\n",
    "            _time = random.randrange(0, max_fade_time)\n",
    "            # _sample_index += _time\n",
    "            wav_data_list.append(ap.noise(random.randrange(0, max_fade_time)))\n",
    "            \n",
    "            # merge to a single np.array\n",
    "            data = np.concatenate(wav_data_list)\n",
    "            # at this point, the generated clip can be exported as wav files\n",
    "            # using scipy.io.wavefile.write(filename, ap.default_fs, data)\n",
    "            \n",
    "            \n",
    "\n",
    "            # count = 0\n",
    "            # sample_index.append((99999999,\"x\"))\n",
    "            # bug = len(data)\n",
    "            # # 320: 每320个sample对应一个audio embedding\n",
    "            # for _sample_index in range(0,len(data),320):\n",
    "            #     if _sample_index > sample_index[count][0] and sample_index[count][1] == 'I':\n",
    "            #         count += 1\n",
    "            #     if _sample_index > sample_index[count][0] and sample_index[count][1] == 'B':\n",
    "            #         count += 1\n",
    "            #         label += beginning_label\n",
    "            #     if _sample_index < sample_index[count][0] and sample_index[count][1] == 'I':\n",
    "            #         label += inside_label\n",
    "            beginning_label = \"1\"\n",
    "            inside_label = \"2\"\n",
    "            outside_label = \"0\"\n",
    "            label = \"\"\n",
    "            window_time = 25  # ms\n",
    "            stride_time = 10  # ms\n",
    "            window_sample_num = 25 * 16  # 16 samples per ms, 16K HZ sample rate\n",
    "            stride_sample_num = 10 * 16\n",
    "            window_median_sample_num = int(window_sample_num / 2)\n",
    "            window_median = get_window_median(len(data), window_sample_num, stride_sample_num)\n",
    "            sample_index, tag = index_queue.get()\n",
    "            for _median in window_median:\n",
    "                if tag == \"B\":\n",
    "                    gap = _median-sample_index\n",
    "                    gap_upper_bound = window_median_sample_num\n",
    "                    gap_lower_bound = window_median_sample_num - stride_sample_num\n",
    "                    if gap >= gap_lower_bound and gap <= gap_upper_bound:\n",
    "                        label += beginning_label\n",
    "                        if not index_queue.is_empty():\n",
    "                            sample_index, tag = index_queue.get()\n",
    "                    else:\n",
    "                        label += outside_label\n",
    "                elif tag == \"I\":\n",
    "                    gap = _median-sample_index\n",
    "                    gap_lower_bound = window_median_sample_num\n",
    "                    if gap > gap_lower_bound:\n",
    "                        label += outside_label\n",
    "                        if not index_queue.is_empty():\n",
    "                            sample_index, tag = index_queue.get()\n",
    "                    else:\n",
    "                        label += inside_label\n",
    "                    \n",
    "            result.append((data, label, pres))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f1bd98-1c08-40f7-84d8-86d6250e5f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['膻中', '肩井', '乳根', '少泽'],\n",
       " [['太冲', '期门'],\n",
       "  ['气海', '足三里'],\n",
       "  ['丰隆', '中脘'],\n",
       "  ['中脘', '足三里'],\n",
       "  ['肝俞', '膈俞'],\n",
       "  ['期门'],\n",
       "  ['中脘', '内关']]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pres[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade1f7a-25eb-46cd-bfe6-f7d140bcc623",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pres, opt in tqdm.tqdm(raw_pres):\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c49ba71-5c23-48ed-98e0-a03f85a83e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 87/87 [07:40<00:00,  5.30s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm \n",
    "all_gen = []\n",
    "for pres, opt in tqdm.tqdm(raw_pres):\n",
    "    all_gen += pres_generate((pres, []), all_words, max_permut=4, repeat=2)\n",
    "    for item in opt:\n",
    "        all_gen += pres_generate((pres, item), all_words, max_permut=4, repeat=2)\n",
    "\n",
    "random.shuffle(all_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc89443-fb63-423a-8631-0bdaad39ed1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated  9330  samples, start write to hard driver.\n"
     ]
    }
   ],
   "source": [
    "len(all_gen)\n",
    "print(\"generated \", len(all_gen), \" samples, start write to hard driver.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed6be1-8505-452c-a3ee-3c973c96f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(len(all_gen))):\n",
    "    data, label = all_gen[i]\n",
    "    file_pref = \"./test2/sample_\" + str(i)\n",
    "    ap.export(file_pref + \".wav\", data)\n",
    "    with open(file_pref + \".txt\", \"w\") as f:\n",
    "        f.write(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550c080-389f-462b-9ac6-99dbc1f36e49",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc28873a-85f1-4699-9a0c-798a1c5eed4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 2176/2176 [09:24<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.881742\n",
      "Recall:    0.900312\n",
      "F1:        0.890930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (Sequential)\n",
    "import tqdm\n",
    "from src.inference import Discriminator\n",
    "\n",
    "model_path = './models/audio_model.pth'\n",
    "labels_csv = './src/class_labels_indices.csv'\n",
    "model = Discriminator(model_path, labels_csv)\n",
    "\n",
    "total_samples = 2176\n",
    "# total_samples = 100\n",
    "\n",
    "file_pref = \"data/combined_prescription/evaluation/\"\n",
    "\n",
    "all_samples = [(file_pref+\"sample_\" + str(i) + \".wav\",\n",
    "                \"\".join(open(file_pref+\"sample_\" + str(i) + \".txt\"))) for i in range(total_samples)]\n",
    "all_samples = [(a, b.strip().split(\"\\t\"))for a, b in all_samples]\n",
    "\n",
    "correct = 0\n",
    "total_pred = 0\n",
    "total_ref = 0\n",
    "\n",
    "for src, ref in tqdm.tqdm(all_samples):\n",
    "    pred = model.inference(src)\n",
    "    correct += sum([1 for item in pred if item in ref])\n",
    "    total_pred += len(pred)\n",
    "    total_ref += len(ref)\n",
    "\n",
    "prec = correct / total_pred\n",
    "recl = correct / total_ref\n",
    "f1 = 2 * prec * recl / (prec + recl)\n",
    "print(\"Precision: %f\" % (correct / total_pred))\n",
    "print(\"Recall:    %f\" % (correct / total_ref))\n",
    "print(\"F1:        %f\" % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d249c-b3ab-4923-8c3b-51ac74912517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_acupoint",
   "language": "python",
   "name": "default_acupoint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
